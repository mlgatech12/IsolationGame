{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your python version is  3.7.6\n",
      "✅ ALL GOOD\n"
     ]
    }
   ],
   "source": [
    "%run helpers/verify_config.py # verify the environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following two lines make sure anything imported from .py scripts \n",
    "# is automatically reloaded if edited & saved (e.g. local unit tests or players)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from board_viz import ReplayGame, InteractiveGame\n",
    "from isolation import Board\n",
    "from test_players import RandomPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Following two lines make sure anything imported from .py scripts \n",
    "# is automatically reloaded if edited & saved (e.g. local unit tests or players)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import player_submission_tests as tests\n",
    "from test_players import HumanPlayer, RandomPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import time\n",
    "from isolation import Board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have discussed this assignment at a whiteboard level, got help from Piazza or have used external resources (not provided by the instructors) that you may want to cite, please do so in the cell below as a python comment! (no need to cite python or included packages documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# Credits if any\n",
    "# 1) Used Piazza posts @155 and @163 to implement node ordering\n",
    "# 2)\n",
    "# 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenMoveEvalFn\n",
    "- This is where you write your evaluation function to evaluate the state of the board.\n",
    "- The test cases below the code are expected to pass locally before you make a submission.\n",
    "- Hints: Remember when calling the below helpful methods that you do need to inform both methods of who your player is (consult those methods' docstrings for more information).\n",
    "\n",
    "Here are a couple methods you might find useful to implement `OpenMoveEvalFn()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OpenMoveEvalFn Test: This board has a score of -4.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class OpenMoveEvalFn:\n",
    "    def score(self, game, my_player=None):\n",
    "        \"\"\"Score the current game state\n",
    "        Evaluation function that outputs a score equal to how many\n",
    "        moves are open for AI player on the board minus how many moves\n",
    "        are open for Opponent's player on the board.\n",
    "\n",
    "        Note:\n",
    "            If you think of better evaluation function, do it in CustomEvalFn below.\n",
    "\n",
    "            Args\n",
    "                game (Board): The board and game state.\n",
    "                my_player (Player object): This specifies which player you are.\n",
    "\n",
    "            Returns:\n",
    "                float: The current state's score. MyMoves-OppMoves.\n",
    "\n",
    "            \"\"\"\n",
    "        # get the length of the move array for player and opponent, substract opponents moves from player moves and return \n",
    "        return len(game.get_player_moves(my_player)) - len(game.get_opponent_moves(my_player))\n",
    "\n",
    "######################################################################\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############\n",
    "######################################################################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "tests.correctOpenEvalFn(OpenMoveEvalFn)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CustomEvalFn:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def score(self, game, my_player=None):\n",
    "        \"\"\"Score the current game state.\n",
    "        \n",
    "        Custom evaluation function that acts however you think it should. This\n",
    "        is not required but highly encouraged if you want to build the best\n",
    "        AI possible.\n",
    "        \n",
    "        Args:\n",
    "            game (Board): The board and game state.\n",
    "            my_player (Player object): This specifies which player you are.\n",
    "            \n",
    "        Returns:\n",
    "            float: The current state's score, based on your own heuristic.\n",
    "        \"\"\"\n",
    "\n",
    "        factor = 1.4\n",
    "        my_moves = len(game.get_player_moves(my_player))\n",
    "        opponent_moves = len(game.get_opponent_moves(my_player))\n",
    "        if(opponent_moves == 0 and my_moves !=0):\n",
    "            return float(\"inf\")\n",
    "        if(opponent_moves != 0 and my_moves == 0):\n",
    "            return float(\"-inf\")       \n",
    "        #moves_played = game.move_count\n",
    "        # calculate percent played - DID NOT WORK\n",
    "        #percent_played = moves_played / (my_moves + opponent_moves + moves_played)\n",
    "        #factor = 2*percent_played\n",
    "        #if (factor < 0.75):\n",
    "        #    factor = 0.75\n",
    "        # calcualte based on total remaining moves - DID NOT WORK\n",
    "        \n",
    "        '''\n",
    "        total_moves = my_moves + opponent_moves\n",
    "        if total_moves > 24:\n",
    "            factor = 0.75\n",
    "        elif total_moves > 12:\n",
    "            factor = 1.25\n",
    "        #elif total_moves > 6:\n",
    "        #    factor = 1.45\n",
    "        \n",
    "        '''\n",
    "        #print(\"Factor: \", factor, \" :: Total moves: \", total_moves)\n",
    "        # calculating based on moves played\n",
    "        moves_played = game.move_count\n",
    "        if moves_played < 6:\n",
    "            factor = 0.75\n",
    "        elif moves_played < 16:\n",
    "            factor = 1.25\n",
    "        \n",
    "        \n",
    "        return my_moves - factor*opponent_moves\n",
    "\n",
    "######################################################################\n",
    "############ DON'T WRITE ANY CODE OUTSIDE THE CLASS! #################\n",
    "######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CustomPlayer:\n",
    "    # TODO: finish this class!\n",
    "    \"\"\"Player that chooses a move using your evaluation function\n",
    "    and a minimax algorithm with alpha-beta pruning.\n",
    "    You must finish and test this player to make sure it properly\n",
    "    uses minimax and alpha-beta to return a good move.\"\"\"\n",
    "\n",
    "    def __init__(self, search_depth=8, eval_fn=CustomEvalFn()):\n",
    "        \"\"\"Initializes your player.\n",
    "        \n",
    "        if you find yourself with a superior eval function, update the default\n",
    "        value of `eval_fn` to `CustomEvalFn()`\n",
    "        \n",
    "        Args:\n",
    "            search_depth (int): The depth to which your agent will search\n",
    "            eval_fn (function): Evaluation function used by your agent\n",
    "        \"\"\"\n",
    "        self.eval_fn = eval_fn\n",
    "        self.search_depth = search_depth\n",
    "    \n",
    "        #self.LTQ = [(0,0), (0,1), (0,2), (1,0), (1,1), (1,2), (2,0), (2,1), (2,2)]\n",
    "        #self.RTQ = [(0,4), (1,4), (2,4), (0,5), (1,5), (2,5), (0,6), (1,6), (2,6)]\n",
    "        #self.LBQ = [(4,0), (4,1), (4,2), (5,0), (5,1), (5,2), (6,0), (6,1), (6,2)]\n",
    "        #self.RBQ = [(4,4), (4,5), (4,6), (5,4), (5,5), (5,6), (6,4), (6,5), (6,6)]\n",
    "    \n",
    "    \n",
    "    def move(self, game, time_left):\n",
    "        \"\"\"Called to determine one move by your agent\n",
    "\n",
    "        Note:\n",
    "            1. Do NOT change the name of this 'move' function. We are going to call\n",
    "            this function directly.\n",
    "            2. Call alphabeta instead of minimax once implemented.\n",
    "        Args:\n",
    "            game (Board): The board and game state.\n",
    "            time_left (function): Used to determine time left before timeout\n",
    "\n",
    "        Returns:\n",
    "            tuple: (int,int): Your best move\n",
    "        \"\"\"\n",
    "        # Trying killer moves functionality\n",
    "        # As explained in class, center of the board is the best first move if available\n",
    "        # if this works, I will move to a proper function\n",
    "        moves = game.get_active_moves()\n",
    "        if (3,3) in moves:\n",
    "            return (3,3)\n",
    "        #elif (3,2) in moves:\n",
    "        #    return (3,2)\n",
    "        #elif (3,4) in moves:\n",
    "        #    return (3,4)\n",
    "        #move_count = game.move_count\n",
    "\n",
    "        '''if move_count < 5:\n",
    "            killer_move = None\n",
    "            curr_position = game.get_active_position()\n",
    "            #moves = game.get_active_moves()\n",
    "            #print(\"Current Position: \", curr_position)\n",
    "            #print(\"Moves: \", moves)\n",
    "            if (curr_position in self.LTQ and (5,6) in moves):\n",
    "                killer_move = (5,6)\n",
    "            elif (curr_position in self.LTQ and (6,5) in moves):\n",
    "                killer_move = (6,5)\n",
    "            elif (curr_position in self.RTQ and (5,0) in moves):\n",
    "                killer_move = (5,0)\n",
    "            elif (curr_position in self.RTQ and (6,1) in moves):\n",
    "                killer_move = (6,1)\n",
    "            elif (curr_position in self.LBQ and (0,5) in moves):\n",
    "                killer_move = (0,5)\n",
    "            elif (curr_position in self.LBQ and (1,6) in moves):\n",
    "                killer_move = (1,6)\n",
    "            elif (curr_position in self.RBQ and (1,0) in moves):\n",
    "                killer_move = (1,0)            \n",
    "            elif (curr_position in self.RBQ and (0,1) in moves):\n",
    "                killer_move = (0,1)            \n",
    "            \n",
    "            #killer_move = cross_move(self, moves, active_position)\n",
    "            if (killer_move is not None):\n",
    "                #print(\"Killer Move:\", killer_move)\n",
    "                #print(\"Game Move Count: \", game.move_count)\n",
    "                return killer_move\n",
    "        '''\n",
    "        #best_move, utility = minimax(self, game, time_left, depth=self.search_depth)\n",
    "        #best_move = alphabeta(self, game, time_left, depth=self.search_depth)\n",
    "        \n",
    "        #traversal_depth = 0\n",
    "        depth = self.search_depth\n",
    "        #if (depth > 4):\n",
    "        #    traversal_depth = 4\n",
    "        #else:\n",
    "        #    traversal_depth = depth\n",
    "\n",
    "        traversal_depth = 4\n",
    "        \n",
    "        # implementing node ordering for section ic\n",
    "        # ideas taken from Piazza post @155 and @163\n",
    "        best_nodes = {}\n",
    "        # run once so that there is no invalid move\n",
    "        move, utility = alphabeta(self, game, time_left, best_nodes, depth=traversal_depth)\n",
    "        \n",
    "        #move, utility = alphabeta(self, game, time_left, best_nodes, depth=traversal_depth)\n",
    "        traversal_depth = traversal_depth + 1\n",
    "\n",
    "        # iterative deepening - take the output only if the traversal completed successfully\n",
    "        while (traversal_depth <= depth and time_left() >= 200):\n",
    "            #print(\"Depth: \", depth, \" :: Traversal Depth: \", traversal_depth)\n",
    "            t_move, t_utility = alphabeta(self, game, time_left, best_nodes, depth=traversal_depth)\n",
    "            if (t_utility != float(\"-inf\") and t_utility != float(\"inf\")):\n",
    "                move = t_move\n",
    "                utility = t_utility\n",
    "            traversal_depth = traversal_depth + 1\n",
    "        return move\n",
    "\n",
    "    def utility(self, game, my_turn):\n",
    "        \"\"\"You can handle special cases here (e.g. endgame)\"\"\"\n",
    "        '''\n",
    "        if(my_turn and game.is_over):\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        if(not my_turn and game.is_over):\n",
    "            return float(\"-inf\")\n",
    "        '''\n",
    "        return self.eval_fn.score(game, self)\n",
    "    \n",
    "###################################################################\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE CLASS! ################\n",
    "###### IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ###########\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def alphabeta(player, game, time_left, best_nodes, depth, alpha=float(\"-inf\"), beta=float(\"inf\"), my_turn=True):\n",
    "    \"\"\"Implementation of the alphabeta algorithm.\n",
    "    \n",
    "    Args:\n",
    "        player (CustomPlayer): This is the instantiation of CustomPlayer() \n",
    "            that represents your agent. It is used to call anything you need \n",
    "            from the CustomPlayer class (the utility() method, for example, \n",
    "            or any class variables that belong to CustomPlayer())\n",
    "        game (Board): A board and game state.\n",
    "        time_left (function): Used to determine time left before timeout\n",
    "        depth: Used to track how deep you are in the search tree\n",
    "        alpha (float): Alpha value for pruning\n",
    "        beta (float): Beta value for pruning\n",
    "        my_turn (bool): True if you are computing scores during your turn.\n",
    "        \n",
    "    Returns:\n",
    "        (tuple, int): best_move, val\n",
    "    \"\"\"\n",
    "    # TODO: finish this function!\n",
    "    #raise NotImplementedError\n",
    "    #return best_move, val\n",
    "    #start with depth 4 and iteratively go deeper\n",
    "    if (my_turn):\n",
    "        t_move, t_utility = max_value_ab(player, game, time_left, best_nodes, depth, alpha, beta, my_turn=True)\n",
    "    else:\n",
    "        t_move, t_utility = min_value_ab(player, game, time_left, best_nodes, depth, alpha, beta, my_turn=False)\n",
    "\n",
    "    return t_move, t_utility\n",
    "\n",
    "# Peter Norvig AI 3rd Edition, Page 170\n",
    "# function MAX-VALUE(state,alpha,beta) returns a utility value\n",
    "#   if TERMINAL-TEST(state) then return UTILITY(state)\n",
    "#     v = - infinity\n",
    "#   for each a in ACTIONS(state) do\n",
    "#     v = MAX(v, MIN-VALUE(RESULT(s,a),alpha,beta))\n",
    "#   if v >= beta then return v\n",
    "#     alpha = MAX(alpha, v)\n",
    "#   return v\n",
    "def max_value_ab(player, game, time_left, best_nodes, depth, alpha, beta, my_turn):\n",
    "    # terminal test\n",
    "    #if (depth == 0):\n",
    "    #    return None, player.utility(game, my_turn)\n",
    "\n",
    "    # no time left (custom player timesout below 70 ms - tried 75,80,65 .. looks like 70 is the key)\n",
    "    if (time_left() <= 70):\n",
    "        #print (\"max_value: Out of time\")\n",
    "        return None, float(\"-inf\") \n",
    "\n",
    "    # find best move from available actions\n",
    "    my_move = None\n",
    "    value = float(\"-inf\")\n",
    "    moves = game.get_active_moves()\n",
    "    if len(moves) == 1:\n",
    "        #print(\"Only 1 move left\")\n",
    "        return moves[0], player.utility(game, my_turn)\n",
    "    if (depth in best_nodes):\n",
    "        best_move = best_nodes[depth]\n",
    "        if (best_move is not None and best_move in moves):\n",
    "            moves.remove(best_move)\n",
    "            moves.insert(0, best_move)\n",
    "    for m in moves:\n",
    "        tmp_board, game_over, winner = game.forecast_move(m)\n",
    "        #check end game per 301\n",
    "        if(not game_over):\n",
    "            #print(\"here\", winner)\n",
    "            if (depth - 1 == 0):\n",
    "                return None, player.utility(tmp_board, my_turn)\n",
    "            tmp_move, tmp_value = min_value_ab(player, tmp_board, time_left, best_nodes, depth - 1, alpha, beta, my_turn)\n",
    "        \n",
    "        else:\n",
    "            tmp_move = m\n",
    "            tmp_value = float(\"inf\")\n",
    "            \n",
    "        if (tmp_value > value):\n",
    "            my_move = m\n",
    "        value = max(value, tmp_value)\n",
    "        if (value >= beta):\n",
    "            best_nodes[depth] = m\n",
    "            return m, value\n",
    "        alpha = max(alpha, value)\n",
    "    best_nodes[depth] = my_move\n",
    "    return my_move, value\n",
    "            \n",
    "# Peter Norvig AI 3rd Edition, Page 170\n",
    "# function MIN-VALUE(state,alpha,beta) returns a utility value\n",
    "#   if TERMINAL-TEST(state) then return UTILITY(state)\n",
    "#     v = + infinity\n",
    "#   for each a in ACTIONS(state) do\n",
    "#     v = MIN(v, MAX-VALUE(RESULT(s,a), alpha, beta))\n",
    "#   if v <= alpha then return v\n",
    "#     beta = MIN(beta, v)\n",
    "#   return v\n",
    "def min_value_ab(player, game, time_left, best_nodes, depth, alpha, beta, my_turn):\n",
    "    # terminal test\n",
    "    #if (depth == 0):\n",
    "    #    return None, player.utility(game, my_turn)\n",
    "\n",
    "    # no time left (custom player timesout below 70 ms - tried 75,80,65 .. looks like 70 is the key)\n",
    "    if (time_left() <= 70):\n",
    "        #print (\"min_value: Out of time\")\n",
    "        return None, float(\"inf\")\n",
    "    \n",
    "    # find best move from available actions\n",
    "    my_move = None\n",
    "    value = float(\"inf\")\n",
    "    moves = game.get_active_moves()\n",
    "    if len(moves) == 1:\n",
    "        #print(\"Only 1 move left\")\n",
    "        return moves[0], player.utility(game, my_turn)\n",
    "    if (depth in best_nodes):\n",
    "        best_move = best_nodes[depth]\n",
    "        if (best_move is not None and best_move in moves):\n",
    "            moves.remove(best_move)\n",
    "            moves.insert(0, best_move)\n",
    "    for m in moves:\n",
    "        tmp_board, game_over, winner = game.forecast_move(m)\n",
    "        if( not game_over):\n",
    "            if (depth - 1 == 0):\n",
    "                return None, player.utility(tmp_board, my_turn)\n",
    "            \n",
    "            tmp_move, tmp_value = max_value_ab(player, tmp_board, time_left, best_nodes, depth - 1, alpha, beta, my_turn)\n",
    "            \n",
    "        else:\n",
    "            tmp_move = m\n",
    "            tmp_value = float(\"-inf\")\n",
    "        \n",
    "        if (tmp_value < value):\n",
    "            my_move = m\n",
    "        value = min(value, tmp_value)\n",
    "        if (value <= alpha):\n",
    "            best_nodes[depth] = m\n",
    "            return m, value\n",
    "        beta = min(beta, value)\n",
    "    best_nodes[depth] = my_move\n",
    "    return my_move, value\n",
    "\n",
    "######################################################################\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############\n",
    "######################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " CustomPlayer - Q1  has won. Reason:  ABPlayer - Q2 has no legal moves left.\n",
      "\n",
      " CustomPlayer - Q1  has won. Reason:  ABPlayer - Q2 has no legal moves left.\n",
      "\n",
      " ABPlayer - Q2  has won. Reason:  CustomPlayer - Q1 has no legal moves left.\n",
      "\n",
      " CustomPlayer - Q1  has won. Reason:  ABPlayer - Q2 has no legal moves left.\n",
      "\n",
      " CustomPlayer - Q1  has won. Reason:  ABPlayer - Q2 has no legal moves left.\n",
      "\n",
      " ABPlayer - Q2  has won. Reason:  CustomPlayer - Q1 has no legal moves left.\n",
      "\n",
      " CustomPlayer - Q1  has won. Reason:  ABPlayer - Q2 has no legal moves left.\n",
      "\n",
      " ABPlayer - Q2  has won. Reason:  CustomPlayer - Q1 has no legal moves left.\n",
      "\n",
      " CustomPlayer - Q1  has won. Reason:  ABPlayer - Q2 has no legal moves left.\n",
      "\n",
      " CustomPlayer - Q1  has won. Reason:  ABPlayer - Q2 has no legal moves left.\n",
      "\n",
      " CustomPlayer - Q2  has won. Reason:  ABPlayer - Q1 has no legal moves left.\n",
      "\n",
      " CustomPlayer - Q2  has won. Reason:  ABPlayer - Q1 has no legal moves left.\n",
      "\n",
      " CustomPlayer - Q2  has won. Reason:  ABPlayer - Q1 has no legal moves left.\n",
      "\n",
      " ABPlayer - Q1  has won. Reason:  CustomPlayer - Q2 has no legal moves left.\n",
      "\n",
      " ABPlayer - Q1  has won. Reason:  CustomPlayer - Q2 has no legal moves left.\n",
      "\n",
      " ABPlayer - Q1  has won. Reason:  CustomPlayer - Q2 has no legal moves left.\n",
      "\n",
      " ABPlayer - Q1  has won. Reason:  CustomPlayer - Q2 has no legal moves left.\n",
      "\n",
      " CustomPlayer - Q2  has won. Reason:  ABPlayer - Q1 has no legal moves left.\n",
      "\n",
      " CustomPlayer - Q2  has won. Reason:  ABPlayer - Q1 has no legal moves left.\n",
      "\n",
      " ABPlayer - Q1  has won. Reason:  CustomPlayer - Q2 has no legal moves left.\n",
      "rounds 20 winners defaultdict(<class 'int'>, {'Games': 20, 'mine': 12, 'theirs': 8})\n"
     ]
    }
   ],
   "source": [
    "tests.play_n_rounds(CustomPlayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "abp_count = 0\n",
    "custom_count = 0\n",
    "for i in range (0,20):\n",
    "    winner, move_history, termination = tests.play(CustomPlayer)\n",
    "    if winner.startswith(\"ABPlayer\"):\n",
    "        abp_count += 1\n",
    "    if winner.startswith(\"CustomPlayer\"):\n",
    "        custom_count += 1\n",
    "print(\"ABP Count: \", abp_count, \" :: Custom Count: \", custom_count)\n",
    "    \n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimax\n",
    "- This is where you will implement the minimax algorithm. The final output of your minimax should come from this method and this is the only method that Gradescope will call when testing minimax.\n",
    "- With MM implemented you are expected to pass: **Defeat a Random Player >=90% of the time.**\n",
    "- Useful functions: The useful methods will probably all come from isolation.py. A couple of particularly interesting ones could be `forecast_move()` and your `score()` method from OpenMoveEvalFn. Remember the double question mark trick from Assignment 0 if you feel you are flipping between files too much!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def minimax(player, game, time_left, depth, my_turn=True):\n",
    "    \"\"\"Implementation of the minimax algorithm.\n",
    "    \n",
    "    Args:\n",
    "        player (CustomPlayer): This is the instantiation of CustomPlayer() \n",
    "            that represents your agent. It is used to call anything you \n",
    "            need from the CustomPlayer class (the utility() method, for example, \n",
    "            or any class variables that belong to CustomPlayer()).\n",
    "        game (Board): A board and game state.\n",
    "        time_left (function): Used to determine time left before timeout\n",
    "        depth: Used to track how deep you are in the search tree\n",
    "        my_turn (bool): True if you are computing scores during your turn.\n",
    "        \n",
    "    Returns:\n",
    "        (tuple, int): best_move, val\n",
    "    \"\"\"\n",
    "    # TODO: finish this function!\n",
    "    #raise NotImplementedError\n",
    "    #print(\"Calling Minimax:\")\n",
    "    if (my_turn):\n",
    "        return max_value(player, game, time_left, depth, my_turn=True)\n",
    "    else:\n",
    "        return min_value(player, game, time_left, depth, my_turn=False)\n",
    "    \n",
    "# Peter Norvig AI 3rd Edition, Page 166\n",
    "# function MAX-VALUE(state) returns a utility value\n",
    "#   if TERMINAL-TEST(state) then return UTILITY(state)\n",
    "#     v = - infinity\n",
    "#   for each a in ACTIONS(state) do\n",
    "#     v = MAX(v, MIN-VALUE(RESULT(s, a)))\n",
    "#   return v\n",
    "def max_value(player, game, time_left, depth, my_turn):\n",
    "    # no time left (custom player timesout below 20 ms)\n",
    "    if (time_left() < 20):\n",
    "        print (\"max_value: Out of time\")\n",
    "        return None, player.utility(game, my_turn) \n",
    "    # terminal test\n",
    "    if (depth == 0):\n",
    "        return None, player.utility(game, my_turn)\n",
    "    # find best move from available actions\n",
    "    else:\n",
    "        my_move = None\n",
    "        value = float(\"-inf\")\n",
    "        moves = game.get_active_moves()\n",
    "        for m in moves:\n",
    "            tmp_board, game_over, winner = game.forecast_move(m)\n",
    "            tmp_move, tmp_value = min_value(player, tmp_board, time_left, depth - 1, my_turn)\n",
    "            if (tmp_value > value):\n",
    "                my_move = m\n",
    "            value = max(value, tmp_value)\n",
    "        return my_move, value\n",
    "            \n",
    "# Peter Norvig AI 3rd Edition, Page 166\n",
    "# function MIN-VALUE(state) returns a utility value\n",
    "#   if TERMINAL-TEST(state) then return UTILITY(state)\n",
    "#     v = ininity\n",
    "#   for each a in ACTIONS(state) do\n",
    "#     v = MIN(v, MAX-VALUE(RESULT(s, a)))\n",
    "#   return v\n",
    "def min_value(player, game, time_left, depth, my_turn):\n",
    "    # no time left (custom player timesout below 20 ms)\n",
    "    if (time_left() < 20):\n",
    "        print (\"min_value: Out of time\")\n",
    "        return None, player.utility(game, my_turn) \n",
    "    # terminal test\n",
    "    if (depth == 0):\n",
    "        return None, player.utility(game, my_turn)\n",
    "    # find best move from available actions\n",
    "    else:\n",
    "        my_move = None\n",
    "        value = float(\"inf\")\n",
    "        moves = game.get_active_moves()\n",
    "        for m in moves:\n",
    "            tmp_board, game_over, winner = game.forecast_move(m)\n",
    "            tmp_move, tmp_value = max_value(player, tmp_board, time_left, depth - 1, my_turn)\n",
    "            if (tmp_value < value):\n",
    "                my_move = m\n",
    "            value = min(value, tmp_value)\n",
    "        return my_move, value\n",
    "\n",
    "######################################################################\n",
    "########## DON'T WRITE ANY CODE OUTSIDE THE FUNCTION! ################\n",
    "######## IF YOU WANT TO CALL OR TEST IT CREATE A NEW CELL ############\n",
    "######################################################################\n",
    "##### CODE BELOW IS USED FOR RUNNING LOCAL TEST DON'T MODIFY IT ######\n",
    "#tests.beatRandom(CustomPlayer)\n",
    "#tests.minimaxTest(CustomPlayer, minimax)\n",
    "################ END OF LOCAL TEST CODE SECTION ######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1a Checkpoint\n",
    "### Now it's a good time to submit for Section1a - See [Exporting the notebook](#Exporting-the-notebook)\n",
    "\n",
    "In case you want to submit please uncomment and run the cell below.\n",
    "\n",
    "Your code will be generated in the folder named `section1a`, please upload `submission.py` file to [Gradescope](https://www.gradescope.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run helpers/notebook2script section1a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlphaBeta\n",
    "- This is where you will implement the alphabeta algorithm. The final output of your alphabeta should come from this method.\n",
    "- With A/B implemented you are expected to pass: **Minimax level 2 >= 70% of the time**\n",
    "- Useful functions: The useful methods will probably all come from `isolation.py`. A couple of particularly interesting ones could be `forecast_move()` and your `score()` method from OpenMoveEvalFn. Remember the double question mark trick from Assignment 0 if you feel you are flipping between files too much!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the lack of a local test above\n",
    "Notice that we do not have any code here. We want you to learn to write your own test cases, so feel free to get creative! You can always create the test in `player_submission_tests.py` and then run it over here in a manner identical to how local tests have been run so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**\n",
    "\n",
    "Now remember that the server (i.e. Gradescope) uses `move()` to interface with your code. So now you will need to update the `move()` method (which you saw earlier in the CustomPlayer class) to call `alphabeta()` so as to return the best move."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1b Checkpoint\n",
    "### Now it's a good time to submit for Section1b - See [Exporting the notebook](#Exporting-the-notebook)\n",
    "\n",
    "In case you want to submit please uncomment and run the cell below.\n",
    "\n",
    "Your code will be generated in the folder named `section1b`. Please upload `submission.py` file to [Gradescope](https://www.gradescope.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run helpers/notebook2script section1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That does not cover all 100 points though!\n",
    "- You're right, and that's on purpose. Each of the bullets below try to walk you through how you may want to think about beating the remaining agents.\n",
    "    - First up is the alphabeta agent. Vanilla alphabeta (that is, alphabeta with no optimization) may not do so well against this agent. However, any agent that searches deeper with the same algorithm probably has a bigger advantage. You may learn about a method that allows your algorithm to search in such a way that you can find the maximum search depth without running out of time. This will probably come up in class or you can read through the book to find out what you are looking for.\n",
    "    - Next to beat is the agent with iterative deepening. This one is a little harder to think about, given that you may have used all the tools that you may think of to try a make a \"better\" agent. But you may have just implemented the evaluation function that was discussed in class. Maybe we can do better - like checking for winning moves and prioritizing those! Or if you are feeling really creative, you can always try editing the `CustomEvalFn` below this cell and come up with an awesome idea of your own.\n",
    "    - Now to Peter's agent with the secret evaluation function. Here we have nothing to tell you. Use everything in your toolbox and within the class rules to defeat it. This is by far the hardest 5 points to get! Good luck and have fun!\n",
    "    \n",
    "- Remember that you may want to edit the methods in the cell with the `CustomPlayer` class to try and implement some of the above. You are certainly free to as long as you adhere to the general rules about editing provided code (which can be found by reading the cell above the `CustomPlayer` code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CustomEvalFn\n",
    "- Edit the below to come up with your very own improved evaluation function. The typical rules about how you can and cannot edit the code we have given (namely, the function signature rules) apply here.\n",
    "- **IMPORTANT**: There's one big thing to keep in mind when the below is exported to `submission.py`. When the export happens, your resulting `submission.py` is parsed top-down, so you may have errors when trying to run that file with a custom evaluation function.\n",
    "    - The fix is to make sure this does not happen is to follow these steps: Use \"Edit->Move Cell Up\" to move the below cell to just above the first time you call CustomEvalFn (probably in CustomPlayer) -> Now run `helpers/notebook.ipynb` -> Submit the resulting `submission.py` to Gradescope to test your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you may need to change the `move()` method again in the CustomPlayer class. In addition, you may also need to edit `eval_fn()` in CustomPlayer to have your agent use the above custom evaluation function when it is playing against the test agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1c Checkpoint\n",
    "### Now it's a good time to submit for Section1c - See [Exporting the notebook](#Exporting-the-notebook)\n",
    "\n",
    "In case you want to submit please uncomment and run the cell below.\n",
    "\n",
    "Your code will be generated in the folder named `section1c`. Please upload `submission.py` file to [Gradescope](https://www.gradescope.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run helpers/notebook2script section1c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Botfight (Extra Credit)\n",
    "\n",
    "In addition to the basic assignment, you will have the option to compete against your peers for the glory of being the **Spring 2020 AI-Game-Playing champ**. We’ll set up a system to pit your AI against others, and we’ll be handing out extra credit for the top players. May the odds be ever in your favor.\n",
    "\n",
    "If you compete in the AI tournament and your agent finishes in the top 10, you will receive bonus points for this assignment **(bonus points are added to the grades of each assignment. Not to final score. )**:\n",
    "\n",
    "- Best Overall:  12 bonus points added to the assignment score.\n",
    "- Second Best: 10 bonus points.\n",
    "- Third Best: 7 bonus points.\n",
    "- Fourth to Tenth Best: 5 bonus points.\n",
    "\n",
    "To make your submission simply upload a file called `submission.py` (similar to what you have been doing so far) with your best agent implementation to Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribute to the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you find any typos and/or have some issues or suggestions on how to improve this or any future assignments, please feel free to create a Pull Request or make a Piazza post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<!-- Hi there! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
